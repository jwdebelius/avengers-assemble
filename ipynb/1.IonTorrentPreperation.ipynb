{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "859fae62-1d76-4bbb-b37e-943e3fae6b90",
   "metadata": {},
   "source": [
    "**Author**: JW Debelius (justine.debelius@ki.se)<br>\n",
    "**Date**: September 2021<br>\n",
    "**Enviroment**: `qiime2-2021.8-dev`<br>\n",
    "**Python version**: 3.8<br>\n",
    "**Extra packages**: None<br>\n",
    "**QIIME version**: 2021.8-dev<br>\n",
    "**Extra Plugins**: q2-sidle (memory refactor); RESCRIPt (v. )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d8979-99df-43ba-9fb2-34431fbfb3c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Mock Community Data Preperation\n",
    "\n",
    "## Background\n",
    "\n",
    "This notebook will process four mock community samples sequenced with the Ion torrent metagenomic kit, originally published by [Barb et al, 2015](https://pubmed.ncbi.nlm.nih.gov/26829716/). In the original paper, the authors profiled four mock communites using the 6 primer proprietary Ion Torrent kit. This kit using 6 primer pairs to target 7 regions along the 16Ss gene with both forward and reverse reads possible.\n",
    "* V2\n",
    "* V3\n",
    "* V4\n",
    "* V67\n",
    "* V8\n",
    "* V9\n",
    "\n",
    "In the original paper, the authors compared the performance for each region compared to the baseline. They clusstered sequences into de novo OTUs clustered with UPARSE; taxonomic assignment was made in QIIME 1 and then compared using abundance profiling, and deviation from published Shannon diversity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae5cab-c1b0-486d-a7f2-cf0d168cbe74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data download and avaliability\n",
    "\n",
    "Sequences were deposided in SRA under accession SUB1054354. We used the [SRA CLI tools]() to download the sequences and the provided sample sheet. Sequence fastq files and the description were saved in the `mock` folder in the `data/input` directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac87ff6-8a03-4739-8b4b-48b909d9de41",
   "metadata": {},
   "source": [
    "When they were deposited, the sequences were demultiplexed by sample, but not by region. The Ion Torrent kit produced reads for 12 regions (6forward and 6 reverse), meaning that to be able to use the sequences here, we need to split them into regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7066cd-56bb-4ba2-b97c-eda255b3a9c7",
   "metadata": {},
   "source": [
    "## Preprocessing Approach\n",
    "\n",
    "For the sake of not hating everyone and everything in existing, we will take a somewhat less optimal approach and try to do a regional demux on  already denoised sequences, because otherwise both I and my computer willcry.         \n",
    "So, Sequenced are prepared through the following steps: \n",
    "\n",
    "1. Sequences from each sample are filtered based on read length into batches based on read length. For this, we'll use 150, 200, 250, and 300 nt reads.\n",
    "2. Import reads for each length using the manifest format \n",
    "3. Denoise the per-region sequences to their fixed read length using dada2-pyro which better handles the error profile. Trim the reads to the approriate read length during sequencing. \n",
    "4. Use RESCRIPt to orient the sequences so they have a consistent orientation\n",
    "5. Align the reads against the reference sequences to seperate them into regions\n",
    "6. Identify he regions through some kind of witch craft\n",
    "7. Filter the sequences into samples and regions\n",
    "8. Account for all the sequences that were lost during filtering, aligning, \n",
    "<!-- 9. Consider life choices and decide why there is such an obsession with mock communitites -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8fa58e-8dbf-436e-8246-9d063f794eb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f60e5f-674c-4ec4-b3bf-e6f764bd0a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import biom\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skbio\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from qiime2 import Artifact, Metadata, Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66101f5a-4c67-44de-bd5c-33b88db18277",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf5da3f-9e25-4e42-b304-fdc7c19517d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'data/inputs/mock/' # modify if you've placed the files in another location\n",
    "output_dir = 'data/output/mock/' # Change this if you want a different output\n",
    "ref_dir = 'data/reference/' # Location of reference files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e38fc-ba0c-4cf5-9152-907dc4290812",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "104038f3-2fb4-498f-b14b-bcad005d46b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = {\n",
    "    'import_seqs': {\n",
    "        'run': True,\n",
    "        'overwrite': True,\n",
    "        'input_dir': input_dir,\n",
    "        'output_dir': os.path.join(output_dir, '1.import'),\n",
    "    },\n",
    "    'denoise_seqs': {\n",
    "        'run': True,\n",
    "        'overwrite': True,\n",
    "        'read_length': 200,\n",
    "        'input_dir':  os.path.join(output_dir, '1.import'),\n",
    "        'output_dir':  os.path.join(output_dir, '2.denoise'),\n",
    "    },\n",
    "    'cluster_orientation': {\n",
    "        'run': True,\n",
    "        'overwrite': True,\n",
    "        'input_dir': os.path.join(output_dir, '2.denoise'),\n",
    "        'output_dir': os.path.join(output_dir, '3.split_orientation'),\n",
    "        'references': {'fwd': 'data/reference/gg_13_8_88/88_otus.qza',\n",
    "                       'rev': 'data/reference/gg_13_8_88/88_otus_rc.qza'},\n",
    "    },\n",
    "    'generate_alignment_reference': {\n",
    "        'run': True,\n",
    "        'input_refs': {\n",
    "            'fwd': 'data/reference/gg_13_8_88/gg_88_otus_aligned.qza',\n",
    "            'rev': 'data/reference/gg_13_8_88/gg_88_otus_aligned_rc.qza',\n",
    "            },\n",
    "        'taxonomy_fp': 'data/reference/gg_13_8_88/88_otu_taxonomy.qza',\n",
    "        'output_refs': {\n",
    "            'fwd': 'data/reference/gg_13_8_88/gg_13_8_aligned_enterobacteraceae_fwd.qza',\n",
    "            'rev': 'data/reference/gg_13_8_88/gg_13_8_aligned_enterobacteraceae_rev.qza',\n",
    "        },\n",
    "        'keep_group': 'f__Enterobacteriaceae',\n",
    "    },\n",
    "    'align_to_reference': {\n",
    "        'run': True,\n",
    "        'overwrite': True,\n",
    "        'seq_input_dir':  os.path.join(output_dir, '3.split_orientation'),\n",
    "        'table_input_dir': os.path.join(output_dir, '2.denoise'),\n",
    "        'output_dir': os.path.join(output_dir, '4.aligned_to_ref'),\n",
    "        'reference_groups': 'f__Enterobacteriaceae',\n",
    "        'references': {'fwd':'data/reference/gg_13_8_88/gg_13_8_aligned_enterobacteraceae_fwd.qza',\n",
    "                       'rev': 'data/reference/gg_13_8_88/gg_13_8_aligned_enterobacteraceae_fwd.qza',\n",
    "                       },\n",
    "    },\n",
    "    'split_to_region': {\n",
    "        'run': True,\n",
    "        'overwrite': True,\n",
    "        'input_map_dir': os.path.join(output_dir, '4.aligned_to_ref'),\n",
    "        'input_data_dir': os.path.join(output_dir, '2.denoise'),\n",
    "        'output_dir': os.path.join(output_dir, '5.regional_demux'),\n",
    "    },\n",
    "    'prepare_database': {\n",
    "        'run': True,\n",
    "        'overwrite': True,\n",
    "        'input_seqs': os.path.join(ref_dir, 'silva/silva-128-99-seqs.qza'),\n",
    "        'input_taxa': os.path.join(ref_dir, 'silva/silva-128-99-taxonomy.qza'),\n",
    "        'input_alignment': os.path.join(ref_dir, 'silva/silva-128-99-aligned-seqs.qza'),\n",
    "        'output_dir': os.path.join(output_dir, '6.database_alignment/'),\n",
    "        'tmp_dir':   os.path.join(output_dir, 'data/output/6.database_alignment/tmp'),\n",
    "    },\n",
    "    'subsample_db': {\n",
    "        'run': True,\n",
    "        'overwrite': True,\n",
    "        'fraction_subsample': 0.1,\n",
    "        'seed': 1776,\n",
    "        'input_alignment': os.path.join(output_dir, '6.database_alignment/silva-128-99-aligned-5-degen-bact-archea-only.qza'),\n",
    "        'output_dir': os.path.join(output_dir, '6.database_alignment/'),\n",
    "    },\n",
    "    'align_regions_for_sub_db': {\n",
    "        'run': True,\n",
    "        'overwrite': True,\n",
    "        'input_db_dir': os.path.join(output_dir, '6.database_alignment/'),\n",
    "        'input_asv_dir': os.path.join(output_dir, '5.regional_demux'),\n",
    "        'output_dir': os.path.join(output_dir, '7.regional_alignment'),\n",
    "        'abundance_thresh': 1000,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4725b26d-acbc-4aab-a5fd-aae3f1361db3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae0f2fe0-dbe6-4923-98e1-79c8c62a7c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [fp.split('.')[0] for fp in os.listdir(input_dir)\n",
    "           if ('_1' in fp) & ('182' in fp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c636e32-ce4c-4496-84e6-e4f7e80d5b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SRR2182222_1', 'SRR2182220_1', 'SRR2182221_1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16fdf25-1032-4d79-9436-55ae352a0698",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "203d4dce-08c8-4320-829d-3d3f8f6fd7ad",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Get preprocessing references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a96ae-664a-4656-ae70-f9559b20fc4f",
   "metadata": {},
   "source": [
    "...|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eac825-aa2e-4541-bc0a-52b2c7e4a2af",
   "metadata": {},
   "source": [
    "### Import the data into QIIME 2 using a manifest format\n",
    "\n",
    "Having split the data from each sample by read length, we'll "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7dcdf85-6ee0-4e80-b097-097ca9bc9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_manifest(samples):\n",
    "    \"\"\"\n",
    "    Builds a sample manifest for a specified read length\n",
    "    \"\"\"\n",
    "    manifest = pd.DataFrame.from_dict(orient='index', data={\n",
    "        sample: {\n",
    "            'absolute-filepath': os.path.abspath(\n",
    "                f'{manifest_input_dir}/{sample}.fastq.gz')\n",
    "        }\n",
    "        for sample in samples\n",
    "    })\n",
    "    manifest.index.set_names('sample-id', inplace=True)\n",
    "    return Metadata(manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "619d023b-c4b0-40cd-9c71-d40d14de0bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mImported data/output/mock/1.import/manifest.tsv as SingleEndFastqManifestPhred33V2 to data/output/mock/1.import/demux_reads.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/1.import/demux_reads.qzv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if steps['import_seqs']['run']:\n",
    "    manifest_input_dir = steps['import_seqs']['input_dir']\n",
    "    manifest_output_dir = steps['import_seqs']['output_dir']\n",
    "    manifest_overwrite = steps['import_seqs']['overwrite']\n",
    "\n",
    "    os.makedirs(manifest_output_dir, exist_ok=manifest_overwrite)\n",
    "    manifest_fp = f'{manifest_output_dir}/manifest.tsv'\n",
    "    seqs_art_fp = f'{manifest_output_dir}/demux_reads.qza'\n",
    "    seqs_vis_fp = f'{manifest_output_dir}/demux_reads.qzv'\n",
    "\n",
    "    manifest = build_manifest(samples)\n",
    "    manifest.save(manifest_fp)\n",
    "\n",
    "    !qiime tools import \\\n",
    "      --type 'SampleData[SequencesWithQuality]' \\\n",
    "      --input-path $manifest_fp \\\n",
    "      --output-path $seqs_art_fp \\\n",
    "      --input-format SingleEndFastqManifestPhred33V2\n",
    "\n",
    "    !qiime demux summarize \\\n",
    "     --i-data $seqs_art_fp \\\n",
    "     --o-visualization $seqs_vis_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1904cc9a-ffd3-474e-be6a-475a8a23d5ed",
   "metadata": {},
   "source": [
    "### Denoise sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5008a6fd-846f-4231-8023-e3527b50588e",
   "metadata": {},
   "source": [
    "The recommendation for Ion Torrent sequencing is to denoise using dada2-denoise pyro **[citeation neededd]** so we'll follow that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08fd8d02-ebfe-4648-910f-c62ac258514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/2.denoise/table_.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/2.denoise/rep_seq.qza\u001b[0m\n",
      "\u001b[32mSaved SampleData[DADA2Stats] to: data/output/mock/2.denoise/denosing_stats.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/2.denoise/denosing_stats.qzv\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/2.denoise/table.qzv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if steps['denoise_seqs']['run']:\n",
    "    denoised_input = steps['denoise_seqs']['input_dir']\n",
    "    denoised_output = steps['denoise_seqs']['output_dir']\n",
    "    denoised_overwrite = steps['denoise_seqs']['overwrite']\n",
    "    length = steps['denoise_seqs']['read_length']\n",
    "    os.makedirs(denoised_output, exist_ok=denoised_overwrite)\n",
    "\n",
    "    seqs_art_fp = f'{denoised_input}/demux_reads.qza'\n",
    "    table_art_fp = f'{denoised_output}/table_.qza'\n",
    "    rep_seq_art_fp = f'{denoised_output}/rep_seq.qza'\n",
    "    stats_art_fp = f'{denoised_output}/denosing_stats.qza'\n",
    "    table_viz_fp = f'{denoised_output}/table.qzv'\n",
    "    stats_viz_fp = f'{denoised_output}/denosing_stats.qzv'\n",
    "\n",
    "    !qiime dada2 denoise-pyro \\\n",
    "     --i-demultiplexed-seqs $seqs_art_fp \\\n",
    "     --p-trunc-len $length \\\n",
    "     --p-hashed-feature-ids \\\n",
    "     --p-n-threads 4 \\\n",
    "     --o-table $table_art_fp \\\n",
    "     --o-representative-sequences $rep_seq_art_fp \\\n",
    "     --o-denoising-stats $stats_art_fp\n",
    "\n",
    "    !qiime metadata tabulate \\\n",
    "     --m-input-file $stats_art_fp \\\n",
    "     --o-visualization $stats_viz_fp\n",
    "\n",
    "    !qiime feature-table summarize \\\n",
    "     --i-table $table_art_fp \\\n",
    "     --o-visualization $table_viz_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf842b29-e465-4f8c-bed6-a6a7912dc23b",
   "metadata": {},
   "source": [
    "And now we have a set of full denoise tables with a fixed read lenght and mixed orientation and region reads. These are now ready for demultiplexing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf5cc8-69fc-4f8f-b9ed-141ed529eb42",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Regional Demultiplexing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534ccb0-7c8f-42da-905a-ae1ecea67508",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split the data into forward and reverse reads\n",
    "\n",
    "We'll split the data by clustering the sequences and then filter to retain the clustered sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d12e7468-64c9-4158-9ed7-8572ffa49d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['table.qzv',\n",
       " 'denosing_stats.qzv',\n",
       " 'table_.qza',\n",
       " 'rep_seq.qza',\n",
       " 'denosing_stats.qza']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(steps['cluster_orientation']['input_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "245274ec-119f-47a1-9e65-8ae4f61c66b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: data/output/mock/3.split_orientation/clustered-seqs-fwd/: No such file or directory\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/3.split_orientation/clustered-seqs-fwd/clustered_table.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/3.split_orientation/clustered-seqs-fwd/clustered_sequences.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/3.split_orientation/clustered-seqs-fwd/unmatched_sequences.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/3.split_orientation/rep-seqs-fwd.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/3.split_orientation/table-fwd.qza\u001b[0m\n",
      "rm: data/output/mock/3.split_orientation/clustered-seqs-rev/: No such file or directory\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/3.split_orientation/clustered-seqs-rev/clustered_table.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/3.split_orientation/clustered-seqs-rev/clustered_sequences.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/3.split_orientation/clustered-seqs-rev/unmatched_sequences.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/3.split_orientation/rep-seqs-rev.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/3.split_orientation/table-rev.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if steps['cluster_orientation']['run']:\n",
    "    cluster_input = steps['cluster_orientation']['input_dir']\n",
    "    cluster_output = steps['cluster_orientation']['output_dir']\n",
    "    cluster_overwrite = steps['cluster_orientation']['overwrite']\n",
    "    cluster_references = steps['cluster_orientation']['references']\n",
    "    cluster_rename = {'fwd': 'rev', 'rev': 'fwd'}\n",
    "    os.makedirs(cluster_output, exist_ok=cluster_overwrite)\n",
    "    \n",
    "    for dir_, ref_seq_fp in cluster_references.items():    \n",
    "        seqs_in_fp = f'{cluster_input}/rep_seq.qza'\n",
    "        table_in_fp = f'{cluster_input}/table_.qza'\n",
    "        cluster_otu_dir = f'{cluster_output}/clustered-seqs-{dir_}/'        \n",
    "        seq_discard_fp = f'{cluster_otu_dir}/unmatched_sequences.qza'\n",
    "        keep_seqs_fp = f'{cluster_output}/rep-seqs-{dir_}.qza'\n",
    "        keep_table_fp = f'{cluster_output}/table-{dir_}.qza'\n",
    "        \n",
    "        # Clusters the sequences closed reference at a low percent identity\n",
    "        !qiime vsearch cluster-features-closed-reference \\\n",
    "         --i-sequences $seqs_in_fp \\\n",
    "         --i-table $table_in_fp \\\n",
    "         --i-reference-sequences $ref_seq_fp \\\n",
    "         --p-perc-identity 0.85 \\\n",
    "         --output-dir $cluster_otu_dir\n",
    "\n",
    "        # Filters the table against the discarded sequences\n",
    "        !qiime feature-table filter-seqs \\\n",
    "         --i-data $seqs_in_fp \\\n",
    "         --m-metadata-file $seq_discard_fp \\\n",
    "         --p-exclude-ids \\\n",
    "         --o-filtered-data $keep_seqs_fp\n",
    "        \n",
    "        !qiime feature-table filter-features \\\n",
    "         --i-table $table_in_fp \\\n",
    "         --m-metadata-file  $keep_seqs_fp \\\n",
    "         --o-filtered-table $keep_table_fp\n",
    "        \n",
    "        !rm -r $cluster_otu_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ae194-76f9-440e-996f-ddcd19f2fa50",
   "metadata": {},
   "source": [
    "### Generate sub alignment references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "681b45f7-75c6-48ad-b3d9-ac27628eb4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if steps['generate_alignment_reference']['run']: \n",
    "    input_refs = steps['generate_alignment_reference']['input_refs']\n",
    "    output_refs = steps['generate_alignment_reference']['output_refs']\n",
    "    taxonomy_fp = steps['generate_alignment_reference']['taxonomy_fp']\n",
    "    keep_group = steps['generate_alignment_reference']['keep_group']\n",
    "\n",
    "    for dir_, input_ in input_refs.items():\n",
    "        output = output_refs[dir_]\n",
    "        if not os.path.exists(output):\n",
    "            !qiime taxa filter-seqs \\\n",
    "             --i-sequences $input_ \\\n",
    "             --i-taxonomy $taxonomy_fp \\\n",
    "             --p-include $keep_group \\\n",
    "             --o-filtered-sequences $output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082cd7f2-52bb-4794-af2a-67f56e0a475e",
   "metadata": {},
   "source": [
    "### Align the oriented reference data and finds the starting positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ad00445-53af-4efd-9450-7c942c7c1419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mQIIME is caching your current deployment for improved performance. This may take a few moments and should only happen once per deployment.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!qiime dev refresh-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "03c2de1f-ee8a-4e32-8ae1-7bbf7dbe0d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureData[AlignedSequence] to: data/output/mock/4.aligned_to_ref/rep_set_aligned_fwd.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[AlignmentPosSummary] to: data/output/mock/4.aligned_to_ref/starts-fwd.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/4.aligned_to_ref/starts-fwd.qzv\u001b[0m\n",
      "\u001b[32mSaved FeatureData[AlignedSequence] to: data/output/mock/4.aligned_to_ref/rep_set_aligned_rev.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[AlignmentPosSummary] to: data/output/mock/4.aligned_to_ref/starts-rev.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/4.aligned_to_ref/starts-rev.qzv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if steps['align_to_reference']['run']: \n",
    "    align_repseq_dir = steps['align_to_reference']['seq_input_dir']\n",
    "    align_table_dir = steps['align_to_reference']['table_input_dir']\n",
    "    align_output_dir = steps['align_to_reference']['output_dir']\n",
    "    align_overwrite = steps['align_to_reference']['overwrite']\n",
    "    align_references =  steps['align_to_reference']['references']\n",
    "\n",
    "    os.makedirs(align_output_dir, exist_ok=align_overwrite)\n",
    "\n",
    "    for dir_, ref_alignment_fp in align_references.items():\n",
    "        rep_seq_fp = f'{align_repseq_dir}/rep-seqs-{dir_}.qza'\n",
    "        table_fp = f'{align_table_dir}/table_.qza'\n",
    "\n",
    "        alignment_fp = \\\n",
    "            f'{align_output_dir}/rep_set_aligned_{dir_}.qza'\n",
    "        output_pos_art = \\\n",
    "            f'{align_output_dir}/starts-{dir_}.qza'\n",
    "        output_pos_viz = \\\n",
    "            f'{align_output_dir}/starts-{dir_}.qzv'\n",
    "\n",
    "        !qiime sidle map-alignment-positions \\\n",
    "         --i-alignment $ref_alignment_fp \\\n",
    "         --i-sequences $rep_seq_fp \\\n",
    "         --i-table $table_fp \\\n",
    "         --p-direction $dir_ \\\n",
    "         --p-no-add-fragments \\\n",
    "         --p-colormap viridis \\\n",
    "         --o-expanded-alignment $alignment_fp \\\n",
    "         --o-position-summary $output_pos_art \\\n",
    "         --o-position-map $output_pos_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "99d009ce-fe01-407a-83c5-f60e0dca2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qiime2 import Visualization\n",
    "# Visualization.load('data/output/mock/4.aligned_to_ref/starts-fwd.qzv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ceabe1ce-9251-451d-accd-98926d20d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization.load('data/output/mock/4.aligned_to_ref/starts-rev.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776fcf2-d26f-4350-84f7-773dcebeb9ff",
   "metadata": {},
   "source": [
    "### Extracts the starting position from the alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be7770-f491-4c07-9e64-4d5ceb525e2e",
   "metadata": {},
   "source": [
    "### Regional Demultiplexing \n",
    "\n",
    "Based on the visualizaation, I can infer a set of starting positions. For the forward reads, I looked at feature with at least 2 sequences and a maxium relative abundnce of at least 1000 sequences. This gives me starting at 69, 303, 508, 914, 1043, 1285 for the forward reads. The reverse positions are a little harder because of the weird split in thata block around 400. But, we also read the starting position backward, so maybe it's not so weird? The reverse reads end up at 349, 534, 805, 1134, 1302, and 1455."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b169d2bf-c194-4d67-9bd1-356a11fd9ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metadata\n",
       "--------\n",
       "137 IDs x 3 columns\n",
       "starting-position: ColumnProperties(type='categorical')\n",
       "sequence-counts:   ColumnProperties(type='numeric')\n",
       "direction:         ColumnProperties(type='categorical')\n",
       "\n",
       "Call to_dataframe() for a tabular representation."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Artifact.load('data/output/mock/4.aligned_to_ref/starts-fwd.qza').view(Metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ad6dcb-c28d-4a62-8f9f-a2d4446d1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_positions = {'fwd': [ 69, 308, 516, 926, 1054, 1301],\n",
    "                   'rev': [340, 541, 815, 1153, 1313, 1466]\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee65714-3932-4d33-ad86-609e790b4fda",
   "metadata": {},
   "source": [
    "I'll use those positions to split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ce8bdc6-8743-43cd-bbed-59ede5ced3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/output/mock/5.regional_demux/table-fwd-69.qza\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/5.regional_demux/table-fwd-69.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-fwd-69.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/5.regional_demux/table-fwd-69.qzv\u001b[0m\n",
      "data/output/mock/5.regional_demux/table-fwd-308.qza\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/5.regional_demux/table-fwd-308.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-fwd-308.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/5.regional_demux/table-fwd-308.qzv\u001b[0m\n",
      "data/output/mock/5.regional_demux/table-fwd-516.qza\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/5.regional_demux/table-fwd-516.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-fwd-516.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/5.regional_demux/table-fwd-516.qzv\u001b[0m\n",
      "data/output/mock/5.regional_demux/table-fwd-926.qza\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/5.regional_demux/table-fwd-926.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-fwd-926.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/5.regional_demux/table-fwd-926.qzv\u001b[0m\n",
      "data/output/mock/5.regional_demux/table-fwd-1054.qza\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/5.regional_demux/table-fwd-1054.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-fwd-1054.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/5.regional_demux/table-fwd-1054.qzv\u001b[0m\n",
      "data/output/mock/5.regional_demux/table-fwd-1301.qza\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/5.regional_demux/table-fwd-1301.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-fwd-1301.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/5.regional_demux/table-fwd-1301.qzv\u001b[0m\n",
      "data/output/mock/5.regional_demux/table-rev-340.qza\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/5.regional_demux/table-rev-340.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-rev-340.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/5.regional_demux/table-rev-340.qzv\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-rev-340.qza\u001b[0m\n",
      "data/output/mock/5.regional_demux/table-rev-541.qza\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/5.regional_demux/table-rev-541.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-rev-541.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/5.regional_demux/table-rev-541.qzv\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-rev-541.qza\u001b[0m\n",
      "data/output/mock/5.regional_demux/table-rev-815.qza\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/5.regional_demux/table-rev-815.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-rev-815.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/5.regional_demux/table-rev-815.qzv\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-rev-815.qza\u001b[0m\n",
      "data/output/mock/5.regional_demux/table-rev-1153.qza\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/5.regional_demux/table-rev-1153.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-rev-1153.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/5.regional_demux/table-rev-1153.qzv\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-rev-1153.qza\u001b[0m\n",
      "data/output/mock/5.regional_demux/table-rev-1313.qza\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/5.regional_demux/table-rev-1313.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-rev-1313.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/5.regional_demux/table-rev-1313.qzv\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-rev-1313.qza\u001b[0m\n",
      "data/output/mock/5.regional_demux/table-rev-1466.qza\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/5.regional_demux/table-rev-1466.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-rev-1466.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: data/output/mock/5.regional_demux/table-rev-1466.qzv\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/5.regional_demux/rep-seq-rev-1466.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if steps['split_to_region']['run']: \n",
    "    region_demux_overwrite = steps['split_to_region']['overwrite']\n",
    "    region_demux_meta_dir = steps['split_to_region']['input_map_dir']\n",
    "    region_demux_data_dir = steps['split_to_region']['input_data_dir']\n",
    "    region_demux_output_dir = steps['split_to_region']['output_dir']\n",
    "\n",
    "    os.makedirs(region_demux_output_dir, exist_ok=region_demux_overwrite)\n",
    "\n",
    "    for dir_, positions in first_positions.items():\n",
    "        for pos in positions:\n",
    "            input_table_fp = f'{region_demux_data_dir}/table_.qza'\n",
    "            input_rep_seq_fp = \\\n",
    "                f'{region_demux_data_dir}/rep_seq.qza'\n",
    "\n",
    "            meta_fp = f'{region_demux_meta_dir}/starts-{dir_}.qza'\n",
    "            \n",
    "            table_fp = \\\n",
    "                f'{region_demux_output_dir}/table-{dir_}-{pos}.qza'\n",
    "            rep_seq_fp = \\\n",
    "                f'{region_demux_output_dir}/rep-seq-{dir_}-{pos}.qza'\n",
    "            table_summary_fp = \\\n",
    "                 f'{region_demux_output_dir}/table-{dir_}-{pos}.qzv'\n",
    "            \n",
    "            where = f'[starting-position]=\"{pos}\"'\n",
    "\n",
    "            !qiime feature-table filter-features \\\n",
    "             --i-table $input_table_fp \\\n",
    "             --m-metadata-file $meta_fp \\\n",
    "             --p-where $where \\\n",
    "             --o-filtered-table $table_fp\n",
    "\n",
    "            !qiime feature-table filter-seqs \\\n",
    "             --i-data $input_rep_seq_fp \\\n",
    "             --i-table $table_fp \\\n",
    "             --o-filtered-data $rep_seq_fp\n",
    "\n",
    "            !qiime feature-table summarize \\\n",
    "             --i-table $table_fp \\\n",
    "             --o-visualization $table_summary_fp\n",
    "\n",
    "            if dir_ == 'rev':\n",
    "                !qiime sidle reverse-complement-sequence \\\n",
    "                 --i-sequence $rep_seq_fp \\\n",
    "                 --o-reverse-complement $rep_seq_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d8c648-1eaa-4b0f-8b23-cac0e3c6a95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20165a59-0a85-45b9-843e-29378c8c125b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Accounting\n",
    "\n",
    "Finally, I'd like to determine how many sequences were lost and where they were lost. For this, I need the dada2 stats... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0d3933a-c926-47fb-bfff-f38888696e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dada2_summaries = \\\n",
    "    Artifact.load(f'data/output/mock/2.denoise/denosing_stats.qza')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2bb233-3448-447f-b243-0b7e517d3553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6523833c-6c15-49ec-86e0-8a64603a2007",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reconstruction\n",
    "\n",
    "## Database\n",
    "\n",
    "We're going to start by pre-filtering the database. For reasons I'm not quite sure I understand, it's not possible to do filtering on the alignmnet sequences directly, so I'm going to filter the reference sequences the way I want them, use *those* to filter the alignmnet set, and then generate a subset of aligned sequences I can use for analysis.\n",
    "<!-- \n",
    "To extract the positions, I'm going to use the most abundant features from each region and align them against the full reference set. For this analysis, I want to work with Silva 128 [cite]. I picked 128 specifically to be able to do phylogenetic tree reconstruction, although at this point, the phylogenny doesns't really matter, so I guess it's more for consistency with the simulated data ¯\\\\\\_(ツ)\\_/¯. I think we've demonstrated the use o fmultiple databases sucessfully, if not I can switch this to greengenes -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2df3e709-c67e-495e-8fe7-4d940ebf4bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if steps['prepare_database']['run']:\n",
    "    prep_db_overwrite = steps['prepare_database']['overwrite']\n",
    "    prep_db_input_seqs = steps['prepare_database']['input_seqs']\n",
    "    prep_db_input_taxa = steps['prepare_database']['input_taxa']\n",
    "    prep_db_input_alignment = steps['prepare_database']['input_alignment']\n",
    "    prep_db_output = steps['prepare_database']['output_dir']\n",
    "    prep_db_tmp_dir = steps['prepare_database']['tmp_dir']\n",
    "\n",
    "    os.makedirs(prep_db_output, exist_ok=prep_db_overwrite)\n",
    "    os.makedirs(prep_db_tmp_dir, exist_ok=True)\n",
    "\n",
    "    !qiime rescript cull-seqs \\\n",
    "     --i-sequences $prep_db_input_seqs \\\n",
    "     --p-num-degenerates 6 \\\n",
    "     --o-clean-sequences $prep_db_tmp_dir/silva-128-99-low-degen.qza \n",
    "\n",
    "    !qiime taxa filter-seqs \\\n",
    "     --i-sequences $prep_db_tmp_dir/silva-128-99-low-degen.qza \\\n",
    "     --i-taxonomy $prep_db_input_taxa \\\n",
    "     --p-include 'D_0__Bact,D_0__Arch' \\\n",
    "     --o-filtered-sequences $prep_db_tmp_dir/silva-128-99-low-degen-bact-archea.qza\n",
    "\n",
    "    !qiime feature-table filter-seqs \\\n",
    "     --i-data $prep_db_input_alignment \\\n",
    "     --m-metadata-file $prep_db_tmp_dir/silva-128-99-low-degen-bact-archea.qza \\\n",
    "     --o-filtered-data $prep_db_output/silva-128-99-aligned-5-degen-bact-archea-only.qza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "364c032e-99e3-43b4-8a2c-920a4c34155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_alignment = Artifact.load(f'{prep_db_output}/silva-128-99-aligned-5-degen-bact-archea-only.qza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14e290ad-e4d4-4934-aeca-c5bdf0f4be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daskjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5887f346-9fc1-4ffe-8f4d-dcb9f4844338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_align_mas.consensus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8288b5-b49b-4837-b10b-239f9c6389d5",
   "metadata": {},
   "source": [
    "And then, we'll subsample the reference to 10% to fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9d5ac76-55c9-4674-8ab5-73cba4d58fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureData[AlignedSequence] to: data/output/mock/6.database_alignment/silva-128-99-aligned-5-degen-bact-archea-only-0.1.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if steps['subsample_db']['run']:\n",
    "    subsample_db_overwrite = steps['subsample_db']['overwrite']\n",
    "    subsample_db_input_alignment = steps['subsample_db']['input_alignment']\n",
    "    subsample_db_fraction = steps['subsample_db']['fraction_subsample']\n",
    "    subsample_db_seed = steps['subsample_db']['seed']\n",
    "    subsample_db_output_dir =  steps['subsample_db']['output_dir']\n",
    "    \n",
    "    os.makedirs(subsample_db_output_dir, exist_ok=subsample_db_overwrite)\n",
    "    \n",
    "    output_alignment = (f'{subsample_db_output_dir}silva-128-99-aligned-'\n",
    "                        f'5-degen-bact-archea-only-{subsample_db_fraction}.qza')\n",
    "    \n",
    "    !qiime rescript subsample-fasta \\\n",
    "     --i-sequences $subsample_db_input_alignment \\\n",
    "     --p-random-seed $subsample_db_seed \\\n",
    "     --p-subsample-size $subsample_db_fraction \\\n",
    "     --o-sample-sequences $output_alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a5cf67-8845-4359-b4e7-0055b57ef240",
   "metadata": {},
   "source": [
    "# Performs regional alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4219c7e4-c2a5-4065-a7bf-9fcc1ac2f9b0",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f50bcf-e95d-4f08-882a-ffc580070b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run': True,\n",
       " 'overwrite': True,\n",
       " 'input_db_dir': 'data/output/mock/6.database_alignment/',\n",
       " 'input_asv_dir': 'data/output/mock/5.regional_demux',\n",
       " 'output_dir': 'data/output/mock/7.regional_alignment',\n",
       " 'abundance_thresh': 1000}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps['align_regions_for_sub_db']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e33194d3-8568-4097-9b51-daef92defcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "align_regions_db_input = steps['align_regions_for_sub_db']['input_db_dir']\n",
    "align_asv_input = steps['align_regions_for_sub_db']['input_asv_dir']\n",
    "\n",
    "align_regions_overwrite = steps['align_regions_for_sub_db']['overwrite']\n",
    "align_asv_out = steps['align_regions_for_sub_db']['output_dir']\n",
    "os.makedirs(align_asv_out, exist_ok=align_regions_overwrite)\n",
    "\n",
    "ref_align = f'{align_regions_db_input}/silva-128-99-aligned-5-degen-bact-archea-only-0.1.qza'\n",
    "\n",
    "dir_ = 'fwd'\n",
    "pos = 308\n",
    "thresh = steps['align_regions_for_sub_db']['abundance_thresh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c0ab4e6-6de1-47be-8964-49d1f48ccb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureTable[Frequency] to: data/output/mock/7.regional_alignment/fwd-308/table.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: data/output/mock/7.regional_alignment/fwd-308/rep-seq.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "region_dir = f'{align_asv_out}/{dir_}-{pos}'\n",
    "os.makedirs(region_dir)\n",
    "\n",
    "full_table_fp = f'{align_asv_input}/table-{dir_}-{pos}.qza'\n",
    "full_repseq_fp = f'{align_asv_input}/rep-seq-{dir_}-{pos}.qza'\n",
    "\n",
    "!qiime feature-table filter-features \\\n",
    " --i-table $full_table_fp \\\n",
    " --p-min-frequency $thresh \\\n",
    " --o-filtered-table $region_dir/table.qza\n",
    "\n",
    "!qiime feature-table filter-seqs \\\n",
    " --i-data $full_repseq_fp \\\n",
    " --i-table $region_dir/table.qza \\\n",
    " --o-filtered-data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04fa87-3ea0-4bde-8e24-2f228504a9b8",
   "metadata": {},
   "source": [
    "And then, I want to preform local regional alignment against the reference for each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54ba56b-7a3c-45f0-99e8-01e585e81893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: \u001b[34mqiime sidle\u001b[0m [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Description: This plugin reconstructs a full 16s sequence from short reads\n",
      "  over a marker gene region using the Short MUltiple Read Framework (SMURF)\n",
      "  algorithm.\n",
      "\n",
      "  Plugin website: https://github.com/jwdebelius/q2-sidle\n",
      "\n",
      "  Getting user support: Please post to the QIIME 2 forum for help with this\n",
      "  plugin: https://forum.qiime2.org\n",
      "\n",
      "\u001b[1mOptions\u001b[0m:\n",
      "  \u001b[34m--version\u001b[0m    Show the version and exit.\n",
      "  \u001b[34m--citations\u001b[0m  Show citations and exit.\n",
      "  \u001b[34m--help\u001b[0m       Show this message and exit.\n",
      "\n",
      "\u001b[1mCommands\u001b[0m:\n",
      "  \u001b[34malign-regional-kmers\u001b[0m            Aligns ASV representative sequences to a\n",
      "                                  regional kmer database.\n",
      "\n",
      "  \u001b[34mfind-alignment-span-positions\u001b[0m   Finds the first and last positions of the\n",
      "                                  representative sequences in the alignment\n",
      "\n",
      "  \u001b[34mfind-and-prepare-regional-seqs\u001b[0m  Extracts kmer sequences from aligned\n",
      "                                  sequences\n",
      "\n",
      "  \u001b[34mfind-first-alignment-position\u001b[0m   Finds the first position of a sequence in an\n",
      "                                  alignment\n",
      "\n",
      "  \u001b[34mmap-alignment-positions\u001b[0m         Finds the starting positions of denoised\n",
      "                                  amplicons in an alignment\n",
      "\n",
      "  \u001b[34mprepare-extracted-region\u001b[0m        Prepares an already extracted region to be a\n",
      "                                  kmer database.\n",
      "\n",
      "  \u001b[34mreconstruct-counts\u001b[0m              Reconstructs multiple aligned regions into a\n",
      "                                  count table.\n",
      "\n",
      "  \u001b[34mreconstruct-database\u001b[0m            Reconstructs regional kmers into full\n",
      "                                  database names\n",
      "\n",
      "  \u001b[34mreconstruct-fragment-rep-seqs\u001b[0m   Reconstract representative sequences for\n",
      "                                  shared fragments.\n",
      "\n",
      "  \u001b[34mreconstruct-taxonomy\u001b[0m            Reconstructs taxonomic strings for a\n",
      "                                  reconstructed sidle table.\n",
      "\n",
      "  \u001b[34mreconstruct-tree\u001b[0m                A pipeline to build a phylogenetic tree\n",
      "                                  based on reconstructed sequences\n",
      "\n",
      "  \u001b[34mreverse-complement-sequence\u001b[0m     Reverse Complements a sequence\n",
      "  \u001b[34msidle-reconstruction\u001b[0m            A pipeline to reconstruct the database,\n",
      "                                  count table, and taxonomy\n",
      "\n",
      "  \u001b[34msummarize-alignment-positions\u001b[0m   Generate a heatmap summarizing the starting\n",
      "                                  position of sequences\n",
      "\n",
      "  \u001b[34mtrim-dada2-posthoc\u001b[0m              Trim a dada2 ASV table and rep set to a\n",
      "                                  consistent length.\n"
     ]
    }
   ],
   "source": [
    "!qiime sidle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac88e5-4102-4eab-8573-343a1a5cf3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
